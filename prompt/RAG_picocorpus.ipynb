{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*beta.*will be renamed.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*gamma.*will be renamed.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step1 加载数据集\n",
    "with open(\"/local/home/sumyao/YSforGIT/dataset/Filtered2Added/picocorpus_nct_filtered_added_withnocluster.json\",'r') as f:\n",
    "    datasets=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=8\n",
    "print(datasets[id].get(\"content\"))\n",
    "pattern = r'[^.]*?clinicaltrials\\.gov[^.]*?NCT\\d{8}[^.]*?\\.'\n",
    "cleaned_abstract = re.sub(pattern, '', datasets[id].get(\"content\"), flags=re.IGNORECASE).strip()\n",
    "retrived_label = datasets[id].get(\"retrieved\")\n",
    "print(retrived_label)\n",
    "participants, interventions, outcomes = retrived_pio_BM25_BERT(cleaned_abstract, retrived_label)\n",
    "print(participants, interventions, outcomes)\n",
    "label = datasets[id].get(\"label\")\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern = r'[^.]*?clinicaltrials\\.gov[^.]*?NCT\\d{8}[^.]*?\\.'\n",
    "cleaned_abstract = re.sub(pattern, '', datasets[id].get(\"content\"), flags=re.IGNORECASE).strip()\n",
    "cleaned_abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.预处理 pubmed clinical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pubmed预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub(r\"-DOCSTART-\", \"\", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r\"[^a-zA-Z0-9.,;?!\\s]\", \"\", sentence)\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    return sentence\n",
    "    \n",
    "def setup_custom_sentencizer(nlp):\n",
    "    @Language.component(\"custom_sentencizer\")\n",
    "    def custom_sentencizer(doc: Doc) -> Doc:\n",
    "        for sent in doc.sents:\n",
    "            if sent.start < len(doc) and doc[sent.start].text[0].islower():\n",
    "                doc[sent.start].is_sent_start = False\n",
    "        return doc\n",
    "    if \"sentencizer\" not in nlp.pipe_names:\n",
    "        nlp.add_pipe(\"sentencizer\", first=True)\n",
    "    nlp.add_pipe(\"custom_sentencizer\", before=\"parser\")\n",
    "    return nlp\n",
    "    \n",
    "cutter = spacy.load(\"en_core_web_sm\")\n",
    "cutter = setup_custom_sentencizer(cutter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clinical预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_value(value):\n",
    "    if not value:\n",
    "        return []\n",
    "    # 如果包含 '|', 按 '|' 分割\n",
    "    parts = value.split('|')\n",
    "    cleaned_parts = []\n",
    "    # 处理每个部分，只保留 ':' 右边的内容\n",
    "    for part in parts:\n",
    "        cleaned = re.sub(r'[()|]', '', part).strip()  # 去除多余字符\n",
    "        if ':' in cleaned:\n",
    "            cleaned = cleaned.split(':', 1)[1].strip()  # 保留冒号右边的内容\n",
    "        cleaned_parts.append(cleaned)\n",
    "    \n",
    "    return cleaned_parts\n",
    "\n",
    "def create_sentences(retrieved):\n",
    "    # 获取数据\n",
    "    age = retrieved.get(\"age\", \"\").strip()\n",
    "    gender = retrieved.get(\"gender\", \"\").strip()\n",
    "    conditions = clean_value(retrieved.get(\"conditions\", \"\"))\n",
    "    interventions = clean_value(retrieved.get(\"interventions\", \"\"))\n",
    "    primary_outcome = retrieved.get(\"primary outcome measures\", \"\").strip()\n",
    "    secondary_outcome = retrieved.get(\"secondary outcome measures\", \"\").strip()\n",
    "\n",
    "    # 合成句子\n",
    "    sentences = []\n",
    "    if gender or age or conditions:\n",
    "        condition_text = \", \".join(conditions)\n",
    "        sentences.append(f\"Patient is a {gender} aged {age} with conditions {condition_text}.\")\n",
    "\n",
    "    if interventions:\n",
    "        interventions_text = \", \".join(interventions)\n",
    "        sentences.append(f\"Interventions may include: {interventions_text}.\")\n",
    "\n",
    "    if primary_outcome:\n",
    "        sentences.append(f\"Primary outcome measures maybe: {primary_outcome}.\")\n",
    "\n",
    "    if secondary_outcome:\n",
    "        sentences.append(f\"Secondary outcome measures maybe: {secondary_outcome}.\")\n",
    "\n",
    "    return sentences\n",
    "\n",
    "# 示例数据\n",
    "\n",
    "retrieved = {\n",
    "    \"age\": \"\",\n",
    "    \"gender\": \"FEMALE\",\n",
    "    \"conditions\": \"Breast Cancer|Osteoporosis\",\n",
    "    \"interventions\": \"DIETARY_SUPPLEMENT: calcium carbonate|DIETARY_SUPPLEMENT: calcium citrate|DIETARY_SUPPLEMENT: cholecalciferol|DRUG: alendronate sodium|DRUG: calcium gluconate|DRUG: risedronate sodium|OTHER: laboratory biomarker analysis|PROCEDURE: dual x-ray absorptometry\",\n",
    "    \"primary outcome measures\": \"Percentage change of bone mineral density (BMD) measured at 2 years (from baseline) in the L1-L4 region of the spine and the hip, 5 years\",\n",
    "    \"secondary outcome measures\": \"Percentage change in BMD at 5 years (from baseline), 5 years|Mean percentage change in BMD at 1, 3, and 5 years (from baseline), 5 years|Proportion of patients without osteopenia or osteoporosis (stratum I) who develop BMD below the absolute threshold for osteopenia (< -2.0 standard deviation below the mean), suffer any osteoporotic fracture, or have an asymptomatic fracture revealed ..., 5 years|Percentage of patients with osteopenia or osteoporosis (stratum II) who have ≥ 5% improvement of BMD at 2 years post randomization on protocol CAN-NCIC-MA27 and who have clinically apparent osteoporosis-related fracture of the long bones, 5 years|Pattern of change in bone biomarkers from baseline, 5 years|Clinical safety and tolerability of study medications, 5 years\"\n",
    "}\n",
    "\n",
    "# 生成句子\n",
    "sentences = create_sentences(retrieved)\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.检索与知识注入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 声明guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidelines_picocorpus='''\n",
    "For Participants, Eight entities are included: the total number of participants in the study, the number of participants in the intervention group, the number of participants in the control group, the condition being treated, eligibility criteria, age, ethnicity, and location. \n",
    "For Intervention and Control, the annotation focuses on specific interventions and control measures charactered with several words used in the study.\n",
    "For Outcomes, the annotation emphasizes intervention-binary-absolute, intervention-binary-percentage, intervention-continous-mean, intervention-continous-standard deviation, intervention-continous-median, intervention-continous-first quartile, intervention-continous-third quartile\n",
    "control-binary-absolute, control-binary-percentage, control-continous-mean, control-continous-standard deviation, control-continous-median, control-continous-first quartile, control-continous-third quartile '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 检索增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step4-1 BM25算法\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "np.random.seed(42)  # 设置种子为42（你可以选择任何整数）\n",
    "\n",
    "\n",
    "# 1. BM25 实现\n",
    "class BM25:\n",
    "    def __init__(self, documents, k1=1.5, b=0.75):\n",
    "        self.documents = documents\n",
    "        self.N = len(documents)  # 文档总数\n",
    "        self.avgdl = sum(len(doc) for doc in documents) / self.N  # 文档平均长度\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.inverted_index = defaultdict(list)  # 倒排索引\n",
    "        self.doc_lengths = []  # 记录每个文档的长度\n",
    "        self.build_index()\n",
    "\n",
    "    def build_index(self):\n",
    "        \"\"\"构建倒排索引并计算每个词项的文档频率和文档长度\"\"\"\n",
    "        for idx, doc in enumerate(self.documents):\n",
    "            self.doc_lengths.append(len(doc))\n",
    "            term_counts = Counter(doc)\n",
    "            for term, freq in term_counts.items():\n",
    "                self.inverted_index[term].append((idx, freq))\n",
    "\n",
    "    def idf(self, term):\n",
    "        \"\"\"计算词项的逆文档频率（IDF）\"\"\"\n",
    "        df = len(self.inverted_index.get(term, []))  # 包含该词的文档数\n",
    "        return math.log((self.N - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "    def score(self, query, doc_idx):\n",
    "        \"\"\"计算查询与指定文档之间的BM25得分\"\"\"\n",
    "        score = 0.0\n",
    "        doc_length = self.doc_lengths[doc_idx]\n",
    "        \n",
    "        term_freqs = {term: freq for term, doc_freqs in self.inverted_index.items() \n",
    "                      for doc, freq in doc_freqs if doc == doc_idx}\n",
    "        for term in query:\n",
    "            if term in term_freqs:\n",
    "                f = term_freqs[term]  # 词频\n",
    "                idf = self.idf(term)  # 逆文档频率\n",
    "                numerator = f * (self.k1 + 1)\n",
    "                denominator = f + self.k1 * (1 - self.b + self.b * doc_length / self.avgdl)\n",
    "                score += idf * (numerator / denominator)\n",
    "        return score\n",
    "\n",
    "    def search(self, query, top_n=1):\n",
    "        \"\"\"对查询进行BM25检索并返回相关性最高的前N个文档\"\"\"\n",
    "        scores = {idx: self.score(query, idx) for idx in range(self.N)}\n",
    "        return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# 2. BERT 相似度计算\n",
    "class BERT:\n",
    "    def __init__(self, documents, bert_model=\"bert-base-uncased\"):\n",
    "        self.documents = documents\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        self.model = BertModel.from_pretrained(bert_model)\n",
    "        self.document_embeddings = self.encode_documents()\n",
    "\n",
    "    def encode_documents(self):\n",
    "        \"\"\"使用 BERT 对文档进行编码\"\"\"\n",
    "        embeddings = []\n",
    "        for doc in self.documents:\n",
    "            sentence = \" \".join(doc)\n",
    "            inputs = self.tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def encode_query(self, query):\n",
    "        \"\"\"使用 BERT 对查询进行编码\"\"\"\n",
    "        sentence = \" \".join(query)\n",
    "        inputs = self.tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "    def bert_similarity(self, query_embedding, doc_idx):\n",
    "        \"\"\"Calculate BERT similarity (cosine similarity)\"\"\"\n",
    "        doc_embedding = self.document_embeddings[doc_idx]\n",
    "        \n",
    "        # Ensure embeddings are numpy arrays\n",
    "        query_embedding = np.array(query_embedding)\n",
    "        doc_embedding = np.array(doc_embedding)\n",
    "        \n",
    "        # Compute cosine similarity using np.matmul (alternative to np.dot)\n",
    "        cos_sim = np.matmul(query_embedding, doc_embedding) / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding))\n",
    "        #print(cos_sim)\n",
    "        return cos_sim\n",
    "\n",
    "\n",
    "# 3. 集成检索（BM25 + BERT）\n",
    "class BM25_BERT:\n",
    "    def __init__(self, documents, k1=1.5, b=0.75, bert_model=\"bert-base-uncased\", alpha=0.5):\n",
    "        self.bm25 = BM25(documents, k1, b)  # 初始化 BM25\n",
    "        self.bert = BERT(documents, bert_model)  # 初始化 BERT\n",
    "        self.alpha = alpha  # 集成的加权系数\n",
    "\n",
    "    def search(self, query, top_n=1):\n",
    "        \"\"\"BM25 和 BERT 集成检索\"\"\"\n",
    "        bm25_scores = {idx: self.bm25.score(query, idx) for idx in range(self.bm25.N)}\n",
    "        query_embedding = self.bert.encode_query(query)\n",
    "        \n",
    "        min_bm25 = min(bm25_scores.values())\n",
    "        max_bm25 = max(bm25_scores.values())\n",
    "        \n",
    "        final_scores = {}\n",
    "        for idx, bm25_score in bm25_scores.items():\n",
    "            # 对 BM25 评分进行归一化\n",
    "            if max_bm25 != min_bm25:  # 避免除以零\n",
    "                bm25_score_norm = (bm25_score - min_bm25) / (max_bm25 - min_bm25)\n",
    "            else:\n",
    "                bm25_score_norm = 0  # 当所有 BM25 分数相同时，归一化后设为 0\n",
    "\n",
    "            # 对 BERT 评分进行归一化\n",
    "            bert_score = self.bert.bert_similarity(query_embedding, idx)\n",
    "            bert_score_norm = (bert_score + 1) / 2  # 将 [-1,1] 映射到 [0,1]\n",
    "            \n",
    "            # 计算最终得分\n",
    "            final_scores[idx] = self.alpha * bm25_score_norm + (1 - self.alpha) * bert_score_norm\n",
    "        #print(f\"BM25 Score for {idx}: {bm25_score}, BERT Score for {idx}: {bert_score}\")\n",
    "\n",
    "        # 返回按分数排序的前 N 个文档\n",
    "        return sorted(final_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "\n",
    "# 4. 检索计算主函数（处理 PIO 类别）\n",
    "def retrived_pio_BM25_BERT(content, retrived_label):\n",
    "    #content_sentences = sent_tokenize(content.replace('The trial is registered at ClinicalTrials',\"\").replace(\"-DOCSTART-\",\"\"))[:-1]  # 段落分句子\n",
    "    doc = cutter(content)\n",
    "    content_sentences=[clean_sentence(str(sent)) for sent in doc.sents]\n",
    "    documents = [item.split() for item in content_sentences]  # 句子转词汇列表, [[]]\n",
    "    #print(documents)\n",
    "    rrf = BM25_BERT(documents)  # 初始化 BM25 + BERT\n",
    "\n",
    "    participants = []\n",
    "    outcomes = []\n",
    "    interventions = []\n",
    "\n",
    "    # 创建检索的句子\n",
    "    sentences = create_sentences(retrived_label)\n",
    "    #print(sentences)\n",
    "    for sentence in sentences:\n",
    "        query = sentence.split()\n",
    "        \n",
    "        # 检索 BM25 和 BERT 集成的结果\n",
    "        results = rrf.search(query, top_n=1)\n",
    "        \n",
    "        # clinical transfer and match（根据查询的第一个词判断类别）\n",
    "        for doc_idx, score in results:\n",
    "            sim_document_content = \" \".join(documents[doc_idx])\n",
    "            first_word = query[0].lower()  # 将第一个词汇转为小写以便匹配\n",
    "            #print(score)\n",
    "            if first_word in [\"age\", \"gender\", \"conditions\"]:\n",
    "                participants.append(sim_document_content)\n",
    "            elif first_word.startswith(\"primary\") or first_word.startswith(\"secondary\"):\n",
    "                outcomes.append(sim_document_content)\n",
    "            else:\n",
    "                interventions.append(sim_document_content)\n",
    "    \n",
    "    return participants, interventions, outcomes\n",
    "\n",
    "\n",
    "\n",
    "# demo示例：如何调用\n",
    "id=11\n",
    "content = datasets[id].get(\"content\")\n",
    "pattern = r'\\b.*?ClinicalTrials\\.gov.*?NCT\\d{8}.*?\\b'\n",
    "cleaned_abstract = re.sub(pattern, '', content)\n",
    "content = re.sub(r'\\n\\s*\\n', '\\n', cleaned_abstract).strip()\n",
    "\n",
    "\n",
    "\n",
    "retrived_label = datasets[id].get(\"retrieved\")\n",
    "\n",
    "participants, interventions, outcomes = retrived_pio_BM25_BERT(content, retrived_label)\n",
    "participants, interventions, outcomes\n",
    "\n",
    "print(\"Participants--------------\", )\n",
    "for p1 in list(set(participants)):\n",
    "    print(p1)\n",
    "print(\"Interventions----------\")\n",
    "for p2 in list(set(interventions))[:2]:\n",
    "    print(p2)\n",
    "print(\"Outcomes----------\")\n",
    "for p3 in list(set(outcomes))[:3]:\n",
    "    print(p3)\n",
    "\n",
    "datasets[id].get(\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.生成模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import random\n",
    "\n",
    "\n",
    "# arg1: instruction\n",
    "instruction='''Your task is to accurately complete the JSON object with a short text phrases and sentences that describe the keys based on provided input, which is the title and abstract of a publication. \n",
    "            The keys are Population, Interventions,  and  Outcomes. \n",
    "            Your response should be like :\"{\"Population\": \"\",\"Interventions\": \"\",\"Outcomes\": \"\"}  \n",
    "            You will be punished if your Response is not a JSON file filled with phrases from input.'''\n",
    "\n",
    "# arg2: input\n",
    "#input=datasets[id].get(\"content\")\n",
    "\n",
    "# arg3: guidelines\n",
    "#guidelines=guidelines_picocorpus\n",
    "\n",
    "# arg4: rag\n",
    "# 确保列表有值，否则设置一个默认值\n",
    "def rag_func(participants, interventions, outcomes):\n",
    "    participant_text = list(set(participants))[0] if participants else \"\"\n",
    "    intervention_text = list(set(interventions))[0] if interventions else \"\"\n",
    "    outcome_text = list(set(outcomes))[0] if outcomes else \"\"\n",
    "    rag = '''Here is the category and corresponding sentence numbering (id) based on SpaCy and initial capitalization:\n",
    "    population :  {},\n",
    "    intervention: {},\n",
    "    outcome: {}\n",
    "    You will get punished if the phrases and values are not extracted from the INPUT.\n",
    "    '''.format(participant_text, intervention_text, outcome_text)\n",
    "    return rag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = \"xxx\"\n",
    "openai.base_url = \"xxx\"\n",
    "openai.default_headers = {\"x-foo\": \"true\"}\n",
    "\n",
    "\n",
    "def generate(instruction, input, rag, guidelines,modelname):\n",
    "    prompt='''### Instruction: {}. \n",
    "            ### Input:{}. \n",
    "            ### RAG:{}\n",
    "            ### Guidelines: {}. \n",
    "            ### Response '''.format(instruction,input,rag,guidelines,\"\")\n",
    "    completion = openai.chat.completions.create(\n",
    "                                        model=modelname,\n",
    "                                        messages=[\n",
    "                                            {\n",
    "                                                \"role\": \"user\",\n",
    "                                                \"content\": prompt,\n",
    "                                            },\n",
    "                                        ],\n",
    "                                    )\n",
    "    response=completion.choices[0].message.content\n",
    "    json_string = response.strip(\"```json\\n\").strip(\"```\").strip()\n",
    "    try:\n",
    "        json_data = json.loads(json_string)\n",
    "        json_response = json.dumps(json_data, ensure_ascii=False, indent=4)\n",
    "        print(json_response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import random\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"sk-hZuBOOA4Ohv18QPNxV4OAhx8VE1A32m1LvWeUKpGWl2dMez4\",\n",
    "    base_url=\"https://api.chatanywhere.tech/v1\"\n",
    ")\n",
    "def generate(instruction, input, rag, guidelines,modelname):\n",
    "    prompt='''### Instruction: {}. \n",
    "            ### Input:{}. \n",
    "            ### RAG:{}\n",
    "            ### Guidelines: {}. \n",
    "            ### Response '''.format(instruction,input,rag,guidelines,\"\")\n",
    "    completion = client.chat.completions.create(\n",
    "                                        model=modelname,\n",
    "                                        messages=[\n",
    "                                            {\n",
    "                                                \"role\": \"user\",\n",
    "                                                \"content\": prompt,\n",
    "                                            },\n",
    "                                        ],\n",
    "                                    )\n",
    "    response=completion.choices[0].message.content\n",
    "    json_string = response.strip(\"```json\\n\").strip(\"```\").strip()\n",
    "    try:\n",
    "        json_data = json.loads(json_string)\n",
    "        json_response = json.dumps(json_data, ensure_ascii=False, indent=4)\n",
    "        print(json_response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results=[]\n",
    "for id in tqdm(range(20),desc=\"Processing examples\"):\n",
    "        content = datasets[id].get(\"content\")\n",
    "        pattern = r'[^.]*?clinicaltrials\\.gov[^.]*?NCT\\d{8}[^.]*?\\.'\n",
    "        content= re.sub(pattern, '', datasets[id].get(\"content\"), flags=re.IGNORECASE).strip()\n",
    "\n",
    "        retrived_label = datasets[id].get(\"retrieved\")\n",
    "        participants, interventions, outcomes = retrived_pio_BM25_BERT(content, retrived_label)\n",
    "        rag=rag_func(participants, interventions, outcomes)\n",
    "\n",
    "        json_onepiece=generate(instruction=instruction,\n",
    "                                input=clean_sentence(content), \n",
    "                                rag=rag, \n",
    "                                guidelines=\"\",\n",
    "                                modelname= \"gpt-4o-mini\")\n",
    "        results.append(json_onepiece)\n",
    "with open('/local/home/sumyao/YSforGIT/output/4o_picocorpus_rag3.json', 'w') as json_file:\n",
    "    json.dump(results, json_file)\n",
    "\n",
    "results=[]\n",
    "for id in tqdm(range(20),desc=\"Processing examples\"):\n",
    "        content = datasets[id].get(\"content\")\n",
    "        ppattern = r'[^.]*?clinicaltrials\\.gov[^.]*?NCT\\d{8}[^.]*?\\.'\n",
    "        content= re.sub(pattern, '', datasets[id].get(\"content\"), flags=re.IGNORECASE).strip()\n",
    "\n",
    "        json_onepiece=generate(instruction=instruction,\n",
    "                                input=clean_sentence(content), \n",
    "                                rag=\"\", \n",
    "                                guidelines=guidelines_picocorpus,\n",
    "                                modelname= \"gpt-4o-mini\")\n",
    "        results.append(json_onepiece)\n",
    "        \n",
    "with open('/local/home/sumyao/YSforGIT/output/4o_picocorpus_guidelines3.json', 'w') as json_file:\n",
    "    json.dump(results, json_file)\n",
    "\n",
    "results=[]\n",
    "for id in tqdm(range(20),desc=\"Processing examples\"):\n",
    "        content = datasets[id].get(\"content\")\n",
    "        pattern = r'[^.]*?clinicaltrials\\.gov[^.]*?NCT\\d{8}[^.]*?\\.'\n",
    "        content= re.sub(pattern, '', datasets[id].get(\"content\"), flags=re.IGNORECASE).strip()\n",
    "        \n",
    "        retrived_label = datasets[id].get(\"retrieved\")\n",
    "        participants, interventions, outcomes = retrived_pio_BM25_BERT(content, retrived_label)\n",
    "        rag=rag_func(participants, interventions, outcomes)\n",
    "\n",
    "        json_onepiece=generate(instruction=instruction,\n",
    "                                input=clean_sentence(content), \n",
    "                                rag=rag, \n",
    "                                guidelines=guidelines_picocorpus,\n",
    "                                modelname= \"gpt-4o-mini\")\n",
    "        results.append(json_onepiece)\n",
    "with open('/local/home/sumyao/YSforGIT/output/4o_picocorpus_rag_guidelines3.json', 'w') as json_file:\n",
    "    json.dump(results, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# annotatiopn是列表形式\n",
    "def preprocess_annotations(annotations):\n",
    "    processed_annotations = []\n",
    "    for annotation in annotations:\n",
    "        processed_annotation = {}\n",
    "        if 'participants' in annotation:\n",
    "            processed_annotation['Population'] = ' '.join(annotation['participants'])  # Ensure it becomes a single string\n",
    "        if 'interventions' in annotation:\n",
    "            interventions = ' '.join(annotation['interventions'])  # Ensure it becomes a single string\n",
    "            if 'comparator' in annotation:\n",
    "                interventions += ' ' + ' '.join(annotation['comparator'])  # 合并comparator到interventions\n",
    "            processed_annotation['Interventions'] = interventions\n",
    "        if 'outcomes' in annotation:\n",
    "            processed_annotation['Outcomes'] = ' '.join(annotation['outcomes'])  # Ensure it's a single string\n",
    "        processed_annotations.append(processed_annotation)\n",
    "    return processed_annotations\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"---input:sentence\n",
    "    ---output: cleaned sentence\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[-/]', ' ', text)\n",
    "    text = re.sub(r'[(),;:-]', '', text)\n",
    "    text = re.sub(r'Not specified', '', text)\n",
    "    text = re.sub(r'not specified', '', text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(annotations, predictions):\n",
    "    p_annotation_text = preprocess_text(''.join(annotations.get('Population', [])))\n",
    "    p_prediction_text = preprocess_text(''.join(predictions.get('Population', [])))\n",
    "    i_annotation_text = preprocess_text(''.join(annotations.get('Interventions', [])))\n",
    "    i_prediction_text = preprocess_text(''.join(predictions.get('Interventions', [])))\n",
    "    o_annotation_text = preprocess_text(''.join(annotations.get('Outcomes', [])))\n",
    "    o_prediction_text = preprocess_text(''.join(predictions.get('Outcomes', [])))\n",
    "\n",
    "    #print(p_annotation_text)\n",
    "    #print(o_prediction_text)\n",
    "\n",
    "    p_precision, p_recall, p_f1, p_correct, p_annotation_len, p_prediction_len = calculate_element_metrics(p_annotation_text, p_prediction_text)\n",
    "    i_precision, i_recall, i_f1, i_correct, i_annotation_len, i_prediction_len = calculate_element_metrics(i_annotation_text, i_prediction_text)\n",
    "    o_precision, o_recall, o_f1, o_correct, o_annotation_len, o_prediction_len = calculate_element_metrics(o_annotation_text, o_prediction_text)\n",
    "\n",
    "    return {\n",
    "        'P': {'precision': p_precision, 'recall': p_recall, 'f1': p_f1},\n",
    "        'I': {'precision': i_precision, 'recall': i_recall, 'f1': i_f1},\n",
    "        'O': {'precision': o_precision, 'recall': o_recall, 'f1': o_f1},\n",
    "    }\n",
    "\n",
    "def calculate_element_metrics(annotation_text, prediction_text):\n",
    "    annotation_words = set(annotation_text.split())\n",
    "    prediction_words = set(prediction_text.split())\n",
    "\n",
    "    intersection = annotation_words.intersection(prediction_words)\n",
    "    union = annotation_words.union(prediction_words)\n",
    "\n",
    "    precision = len(intersection) / len(prediction_words) if len(prediction_words) > 0 else 0\n",
    "    recall = len(intersection) / len(annotation_words) if len(annotation_words) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1, len(intersection), len(annotation_words), len(prediction_words)\n",
    "\n",
    "\n",
    "def calculate_macro_avg(metrics):\n",
    "    # 初始化三个要素的累计精度、召回率、F1分数\n",
    "    p_precision_total, p_recall_total, p_f1_total = 0, 0, 0\n",
    "    i_precision_total, i_recall_total, i_f1_total = 0, 0, 0\n",
    "    o_precision_total, o_recall_total, o_f1_total = 0, 0, 0\n",
    "    count = len(metrics)\n",
    "\n",
    "    # 累加每个要素的指标\n",
    "    for metric in metrics:\n",
    "        p_precision_total += metric['P']['precision']\n",
    "        p_recall_total += metric['P']['recall']\n",
    "        p_f1_total += metric['P']['f1']\n",
    "\n",
    "        i_precision_total += metric['I']['precision']\n",
    "        i_recall_total += metric['I']['recall']\n",
    "        i_f1_total += metric['I']['f1']\n",
    "\n",
    "        o_precision_total += metric['O']['precision']\n",
    "        o_recall_total += metric['O']['recall']\n",
    "        o_f1_total += metric['O']['f1']\n",
    "\n",
    "    # 计算宏平均\n",
    "    p_precision_avg = p_precision_total / count if count > 0 else 0\n",
    "    p_recall_avg = p_recall_total / count if count > 0 else 0\n",
    "    p_f1_avg = p_f1_total / count if count > 0 else 0\n",
    "\n",
    "    i_precision_avg = i_precision_total / count if count > 0 else 0\n",
    "    i_recall_avg = i_recall_total / count if count > 0 else 0\n",
    "    i_f1_avg = i_f1_total / count if count > 0 else 0\n",
    "\n",
    "    o_precision_avg = o_precision_total / count if count > 0 else 0\n",
    "    o_recall_avg = o_recall_total / count if count > 0 else 0\n",
    "    o_f1_avg = o_f1_total / count if count > 0 else 0\n",
    "\n",
    "    # 返回各个要素的平均结果\n",
    "    return {\n",
    "        'P': {'precision': p_precision_avg, 'recall': p_recall_avg, 'f1': p_f1_avg},\n",
    "        'I': {'precision': i_precision_avg, 'recall': i_recall_avg, 'f1': i_f1_avg},\n",
    "        'O': {'precision': o_precision_avg, 'recall': o_recall_avg, 'f1': o_f1_avg}\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def calculate_micro_avg(metrics):\n",
    "    # 初始化三个要素的累计统计\n",
    "    p_correct, p_annotation_total, p_prediction_total = 0, 0, 0\n",
    "    i_correct, i_annotation_total, i_prediction_total = 0, 0, 0\n",
    "    o_correct, o_annotation_total, o_prediction_total = 0, 0, 0\n",
    "\n",
    "    # 累计每个要素的统计值\n",
    "    for metric in metrics:\n",
    "        # P\n",
    "        p_correct += metric['P']['precision'] * metric['P']['f1']  # 假设使用交集数量作为正确预测\n",
    "        p_annotation_total += metric['P']['recall']  # 注释的单词数\n",
    "        p_prediction_total += metric['P']['f1']  # 预测的单词数\n",
    "\n",
    "        # I\n",
    "        i_correct += metric['I']['precision'] * metric['I']['f1']\n",
    "        i_annotation_total += metric['I']['recall']\n",
    "        i_prediction_total += metric['I']['f1']\n",
    "\n",
    "        # O\n",
    "        o_correct += metric['O']['precision'] * metric['O']['f1']\n",
    "        o_annotation_total += metric['O']['recall']\n",
    "        o_prediction_total += metric['O']['f1']\n",
    "\n",
    "    # 分别计算三个要素的微观平均\n",
    "    def calculate_avg(correct, annotation_total, prediction_total):\n",
    "        precision = correct / prediction_total if prediction_total > 0 else 0\n",
    "        recall = correct / annotation_total if annotation_total > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return precision, recall, f1\n",
    "\n",
    "    p_precision, p_recall, p_f1 = calculate_avg(p_correct, p_annotation_total, p_prediction_total)\n",
    "    i_precision, i_recall, i_f1 = calculate_avg(i_correct, i_annotation_total, i_prediction_total)\n",
    "    o_precision, o_recall, o_f1 = calculate_avg(o_correct, o_annotation_total, o_prediction_total)\n",
    "\n",
    "    # 返回结果\n",
    "    return {\n",
    "        'P': {'precision': p_precision, 'recall': p_recall, 'f1': p_f1},\n",
    "        'I': {'precision': i_precision, 'recall': i_recall, 'f1': i_f1},\n",
    "        'O': {'precision': o_precision, 'recall': o_recall, 'f1': o_f1}\n",
    "    }\n",
    "\n",
    "def calculate_total_macro_avg(macro_avg):\n",
    "    # 总宏平均：取 P、I、O 的 Precision、Recall 和 F1 的均值\n",
    "    total_macro_precision = (macro_avg['P']['precision'] + macro_avg['I']['precision'] + macro_avg['O']['precision']) / 3\n",
    "    total_macro_recall = (macro_avg['P']['recall'] + macro_avg['I']['recall'] + macro_avg['O']['recall']) / 3\n",
    "    total_macro_f1 = (macro_avg['P']['f1'] + macro_avg['I']['f1'] + macro_avg['O']['f1']) / 3\n",
    "    return total_macro_precision, total_macro_recall, total_macro_f1\n",
    "\n",
    "def calculate_total_micro_avg(micro_avg):\n",
    "    # 总微观平均：取 P、I、O 的 Precision、Recall 和 F1 的均值\n",
    "    total_micro_precision = (micro_avg['P']['precision'] + micro_avg['I']['precision'] + micro_avg['O']['precision']) / 3\n",
    "    total_micro_recall = (micro_avg['P']['recall'] + micro_avg['I']['recall'] + micro_avg['O']['recall']) / 3\n",
    "    total_micro_f1 = (micro_avg['P']['f1'] + micro_avg['I']['f1'] + micro_avg['O']['f1']) / 3\n",
    "    return total_micro_precision, total_micro_recall, total_micro_f1\n",
    "\n",
    "\n",
    "individual_metrics = []\n",
    "individual_metrics = []\n",
    "annotations=[item['label'] for item in datasets][:20]\n",
    "processed_annotations = preprocess_annotations(annotations)\n",
    "\n",
    "# 假设 annotations_list 和 predictions_list 已经正确填充\n",
    "'''\n",
    "for path in ['/local/home/sumyao/YSforGIT/output/final/4o_picocorpus3.json',\n",
    "             '/local/home/sumyao/YSforGIT/output/final/4o_picocorpus_rag3.json',\n",
    "             '/local/home/sumyao/YSforGIT/output/final/4o_picocorpus_guidelines3.json',\n",
    "             '/local/home/sumyao/YSforGIT/output/final/4o_picocorpus_rag_guidelines3.json']:'''\n",
    "for path in [#'/local/home/sumyao/YSforGIT/output/4o_picocorpus.json',\n",
    "             '/local/home/sumyao/YSforGIT/output/4o_picocorpus_rag3.json',\n",
    "             '/local/home/sumyao/YSforGIT/output/4o_picocorpus_guidelines3.json',\n",
    "             '/local/home/sumyao/YSforGIT/output/4o_picocorpus_rag_guidelines3.json']:\n",
    "    predictions = json.load(open(path))\n",
    "    predictions = [json.loads(item) for item in predictions]\n",
    "\n",
    "    # 在这里我们假设 annotations_list 已经是一个经过处理的字典列表\n",
    "    annotations_list = processed_annotations  # 这个列表包含处理后的注释字典\n",
    "    predictions_list = predictions\n",
    "    print(len(annotations_list),len(predictions_list))\n",
    "\n",
    "    for i in range(len(annotations_list)):\n",
    "        metrics = calculate_metrics(annotations_list[i], predictions_list[i])\n",
    "        \n",
    "        '''# 输出每个要素的评估结果\n",
    "        print(f\"Element {i + 1}:\")\n",
    "        for key in metrics:\n",
    "            print(f\"{key} - Precision: {metrics[key]['precision']:.4f}, Recall: {metrics[key]['recall']:.4f}, F1: {metrics[key]['f1']:.4f}\")\n",
    "'''\n",
    "        individual_metrics.append(metrics)\n",
    "\n",
    "    # 计算宏平均\n",
    "    macro_avg = calculate_macro_avg(individual_metrics)\n",
    "    print(\"\\nMacro Average Results:\")\n",
    "    for key in macro_avg:\n",
    "        print(f\"{key} - Precision: {macro_avg[key]['precision']:.4f}, Recall: {macro_avg[key]['recall']:.4f}, F1: {macro_avg[key]['f1']:.4f}\")\n",
    "\n",
    "    # 计算微观平均\n",
    "    micro_avg = calculate_micro_avg(individual_metrics)\n",
    "    print(\"\\nMicro Average Results:\")\n",
    "    for key in micro_avg:\n",
    "        print(f\"{key} - Precision: {micro_avg[key]['precision']:.4f}, Recall: {micro_avg[key]['recall']:.4f}, F1: {micro_avg[key]['f1']:.4f}\")\n",
    "\n",
    "    # 计算总宏平均\n",
    "    total_macro_precision, total_macro_recall, total_macro_f1 = calculate_total_macro_avg(macro_avg)\n",
    "    print(\"\\nTotal Macro Average:\")\n",
    "    print(f\"Precision: {total_macro_precision:.4f}, Recall: {total_macro_recall:.4f}, F1: {total_macro_f1:.4f}\")\n",
    "\n",
    "    # 计算总微观平均\n",
    "    total_micro_precision, total_micro_recall, total_micro_f1 = calculate_total_micro_avg(micro_avg)\n",
    "    print(\"\\nTotal Micro Average:\")\n",
    "    print(f\"Precision: {total_micro_precision:.4f}, Recall: {total_micro_recall:.4f}, F1: {total_micro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
